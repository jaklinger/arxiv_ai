{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "from alphabet_detector import AlphabetDetector\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy import text as sql_text\n",
    "\n",
    "# Inputs for the MAK POST request, including the API key\n",
    "HEADERS = {\n",
    "    'Ocp-Apim-Subscription-Key': 'a9a9efa851b44d5bbd6c841215a99e00',\n",
    "    'Content-Type': 'application/x-www-form-urlencoded'\n",
    "}\n",
    "\n",
    "# Fields to return from MAK\n",
    "FIELDS = [\"Id\",\"Ti\",\"D\",\"AA.AuN\",\"AA.AuId\",\"F.FId\",\"L\",\"C.CN\",\"E\",\n",
    "          \"J.JId\",\"AA.AfId\",\"CC\",\"ECC\",\"AA.AfN\",\"J.JN\"]\n",
    "\n",
    "\n",
    "class TitleProcessor(AlphabetDetector):\n",
    "    '''Processes a pure utf-8 title into something ready for a MAK query.'''\n",
    "    def process_title(self, title):\n",
    "        # Get replace non-alphanums (allowing foreign characters)\n",
    "        result = \"\".join([x\n",
    "                          if len(self.detect_alphabet(x)) > 0\n",
    "                          or x.isnumeric()\n",
    "                          else \" \" for x in title.lower()])\n",
    "        # Replace double-spaces with single-spaces\n",
    "        while \"  \" in result:\n",
    "            result = result.replace(\"  \",\" \")        \n",
    "        return result\n",
    "\n",
    "\n",
    "'''Find matches to titles from the MAK database.\n",
    "\n",
    "    raw_titles: A list of titles in the form (id, title)\n",
    "    call_limit: The maximum number of MAK API calls. \n",
    "                NB: Nesta's allowance is 10,000 per month.\n",
    "'''\n",
    "def mak_from_titles(raw_titles, call_limit, optional_columns):\n",
    "\n",
    "    # Make arXiv titles match MAK title format (strip non-alphanums,\n",
    "    # allowing foreign chars)\n",
    "    tp = TitleProcessor()\n",
    "    titles = [(pid,tp.process_title(t)) for pid,t in raw_titles]\n",
    "    # Maximum of title_count titles, returning query_count results\n",
    "    title_count = 600\n",
    "    title_offset = 0\n",
    "    query_count = 1000\n",
    "\n",
    "    # Count the number of calls for book-keeping\n",
    "    calls = 0\n",
    "\n",
    "    # Iterate until done\n",
    "    data = []\n",
    "    while title_offset < len(titles):\n",
    "        # A soft limit so that we don't overrun the API limit\n",
    "        if calls >= call_limit:\n",
    "            break\n",
    "        calls += 1\n",
    "\n",
    "        # Get the index of the final title\n",
    "        last_title = title_offset+title_count\n",
    "        # Python indexing [n:None] will return n --> end\n",
    "        if last_title > len(titles):\n",
    "            last_title = None\n",
    "        # Get the title subset for this query\n",
    "        titles_subset = titles[title_offset:last_title]\n",
    "        title_offset += title_count        \n",
    "\n",
    "        # Generate the MAK query (OR statement of titles (Ti))\n",
    "        expr = [\"Ti='\"+t+\"'\" for _,t in titles_subset]\n",
    "        print(\"Posting\",len(expr),\"queries\")\n",
    "        expr = ','.join(expr)\n",
    "        expr = \"expr=OR(\"+expr+\")\"\n",
    "        \n",
    "        # Write and launch the query\n",
    "        query = expr+\"&count=\"+str(query_count)+\"&attributes=\"+\",\".join(FIELDS)\n",
    "        r = requests.post('https://westus.api.cognitive.microsoft.com/academic/v1.0/evaluate',\n",
    "                          data=query.encode(\"utf-8\"), headers=HEADERS)\n",
    "        try:\n",
    "            js = r.json()\n",
    "        except json.decoder.JSONDecodeError as err:\n",
    "            print(\"Error with status code \",r.status_code)\n",
    "            print(r.text)\n",
    "            raise err\n",
    "        # Print out some stats\n",
    "        print(\"Got\",len(js[\"entities\"]),\"results\")\n",
    "        \n",
    "        # Append the results to the output\n",
    "        for pid,t in titles_subset:\n",
    "            # Flag in case no match is found\n",
    "            matched = False\n",
    "            for row in js[\"entities\"]:                \n",
    "                if t != row[\"Ti\"]:\n",
    "                    continue\n",
    "                matched = True\n",
    "                break\n",
    "            # Default in case no match is found\n",
    "            if not matched:\n",
    "                data.append(dict(pid=pid,title=t,matched=False))\n",
    "                continue\n",
    "            # If a match was found, extract info        \n",
    "            insts = list(set(author[\"AfN\"] for author in row[\"AA\"] if \"AfN\" in author))\n",
    "\n",
    "            # Convert \"extended metadata\" (E) to json, then extract arxiv IDs\n",
    "            arxiv_sources = []\n",
    "            if \"E\" in row:\n",
    "                if type(row[\"E\"]) is not dict:\n",
    "                    row[\"E\"] = json.loads(row[\"E\"])\n",
    "                if 'S' in row[\"E\"]:\n",
    "                    for source in row[\"E\"][\"S\"]:\n",
    "                        if \"U\" not in source:\n",
    "                            continue\n",
    "                        if not source['U'].startswith(\"https://arxiv.org/\"):\n",
    "                            continue\n",
    "                        arxiv_sources.append(source['U'])\n",
    "                # Add then mandatory fields\n",
    "            data_row = dict(pid=pid,title=t, institutes=insts, arxiv_sources=arxiv_sources,\n",
    "                            citations=row[\"CC\"], date=row[\"D\"], matched=True)            \n",
    "            # Then add optional fields\n",
    "            for long, short in optional_columns.items():                \n",
    "                second = None\n",
    "                if \".\" in short:\n",
    "                    short, second = short.split(\".\")\n",
    "                if short in row:\n",
    "                    if second is None:\n",
    "                        data_row[long] = row[short]\n",
    "                    elif second in row[short]:\n",
    "                        data_row[long] = row[short][second]\n",
    "            data.append(data_row)\n",
    "            \n",
    "    # Print summary statistics\n",
    "    nmatch = 0 \n",
    "    nboth = 0\n",
    "    for row in data:\n",
    "        if not row[\"matched\"]:\n",
    "            continue\n",
    "        nmatch += 1\n",
    "        if row[\"citations\"] > 0 and len(row[\"institutes\"]) > 0:\n",
    "            nboth += 1\n",
    "    print(\"Made\",calls,\"calls\")\n",
    "    print(\"Got\",nmatch,\"matches from\",len(data),\"queries, of which\",\n",
    "          nboth,\"contained both institutes and citation information\")\n",
    "    # Done\n",
    "    return data\n",
    "\n",
    "# Stolen from https://stackoverflow.com/a/434328/1571593\n",
    "def chunker(seq, size):\n",
    "    return (seq[pos:pos + size] for pos in range(0, len(seq), size))\n",
    "\n",
    "# Execute IN statements in chunks\n",
    "def execute_IN_in_chunks(con, query, chunkable, chunk_size):\n",
    "    output = []\n",
    "    for chunk in chunker(chunkable, chunk_size):\n",
    "        result = con.execute(sql_text(query), values=tuple(chunk))\n",
    "        output += result.fetchall()\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Match CS arxiv articles to MAG API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posting 600 queries\n",
      "Got 613 results\n",
      "Posting 600 queries\n",
      "Got 595 results\n",
      "Posting 600 queries\n",
      "Got 436 results\n",
      "Posting 600 queries\n",
      "Got 552 results\n",
      "Posting 600 queries\n",
      "Got 611 results\n",
      "Posting 600 queries\n",
      "Got 647 results\n",
      "Posting 600 queries\n",
      "Got 643 results\n",
      "Posting 600 queries\n",
      "Got 636 results\n",
      "Posting 600 queries\n",
      "Got 652 results\n",
      "Posting 600 queries\n",
      "Got 643 results\n",
      "Posting 600 queries\n",
      "Got 628 results\n",
      "Posting 600 queries\n",
      "Got 636 results\n",
      "Posting 600 queries\n",
      "Got 659 results\n",
      "Posting 600 queries\n",
      "Got 617 results\n",
      "Posting 600 queries\n",
      "Got 635 results\n",
      "Posting 600 queries\n",
      "Got 645 results\n",
      "Posting 600 queries\n",
      "Got 631 results\n",
      "Posting 600 queries\n",
      "Got 619 results\n",
      "Posting 600 queries\n",
      "Got 590 results\n",
      "Posting 600 queries\n",
      "Got 535 results\n",
      "Posting 600 queries\n",
      "Got 578 results\n",
      "Posting 600 queries\n",
      "Got 616 results\n",
      "Posting 600 queries\n",
      "Got 603 results\n",
      "Posting 600 queries\n",
      "Got 593 results\n",
      "Posting 600 queries\n",
      "Got 626 results\n",
      "Posting 600 queries\n",
      "Got 638 results\n",
      "Posting 600 queries\n",
      "Got 604 results\n",
      "Posting 600 queries\n",
      "Got 618 results\n",
      "Posting 600 queries\n",
      "Got 578 results\n",
      "Posting 600 queries\n",
      "Got 622 results\n",
      "Posting 600 queries\n",
      "Got 594 results\n",
      "Posting 600 queries\n",
      "Got 625 results\n",
      "Posting 600 queries\n",
      "Got 612 results\n",
      "Posting 600 queries\n",
      "Got 609 results\n",
      "Posting 600 queries\n",
      "Got 617 results\n",
      "Posting 600 queries\n",
      "Got 592 results\n",
      "Posting 600 queries\n",
      "Got 626 results\n",
      "Posting 600 queries\n",
      "Got 597 results\n",
      "Posting 600 queries\n",
      "Got 596 results\n",
      "Posting 600 queries\n",
      "Got 584 results\n",
      "Posting 600 queries\n",
      "Got 618 results\n",
      "Posting 600 queries\n",
      "Got 624 results\n",
      "Posting 600 queries\n",
      "Got 601 results\n",
      "Posting 600 queries\n",
      "Got 608 results\n",
      "Posting 600 queries\n",
      "Got 604 results\n",
      "Posting 600 queries\n",
      "Got 591 results\n",
      "Posting 600 queries\n",
      "Got 622 results\n",
      "Posting 600 queries\n",
      "Got 597 results\n",
      "Posting 600 queries\n",
      "Got 599 results\n",
      "Posting 600 queries\n",
      "Got 587 results\n",
      "Posting 600 queries\n",
      "Got 602 results\n",
      "Posting 600 queries\n",
      "Got 632 results\n",
      "Posting 600 queries\n",
      "Got 590 results\n",
      "Posting 600 queries\n",
      "Got 601 results\n",
      "Posting 600 queries\n",
      "Got 577 results\n",
      "Posting 600 queries\n",
      "Got 576 results\n",
      "Posting 600 queries\n",
      "Got 594 results\n",
      "Posting 600 queries\n",
      "Got 597 results\n",
      "Posting 600 queries\n",
      "Got 580 results\n",
      "Posting 600 queries\n",
      "Got 583 results\n",
      "Posting 600 queries\n",
      "Got 596 results\n",
      "Posting 600 queries\n",
      "Got 605 results\n",
      "Posting 600 queries\n",
      "Got 599 results\n",
      "Posting 600 queries\n",
      "Got 586 results\n",
      "Posting 600 queries\n",
      "Got 586 results\n",
      "Posting 600 queries\n",
      "Got 602 results\n",
      "Posting 600 queries\n",
      "Got 596 results\n",
      "Posting 600 queries\n",
      "Got 611 results\n",
      "Posting 600 queries\n",
      "Got 592 results\n",
      "Posting 600 queries\n",
      "Got 589 results\n",
      "Posting 600 queries\n",
      "Got 584 results\n",
      "Posting 600 queries\n",
      "Got 593 results\n",
      "Posting 600 queries\n",
      "Got 589 results\n",
      "Posting 600 queries\n",
      "Got 603 results\n",
      "Posting 600 queries\n",
      "Got 577 results\n",
      "Posting 600 queries\n",
      "Got 576 results\n",
      "Posting 600 queries\n",
      "Got 580 results\n",
      "Posting 600 queries\n",
      "Got 608 results\n",
      "Posting 600 queries\n",
      "Got 601 results\n",
      "Posting 600 queries\n",
      "Got 620 results\n",
      "Posting 600 queries\n",
      "Got 583 results\n",
      "Posting 600 queries\n",
      "Got 589 results\n",
      "Posting 600 queries\n",
      "Got 577 results\n",
      "Posting 600 queries\n",
      "Got 579 results\n",
      "Posting 600 queries\n",
      "Got 623 results\n",
      "Posting 600 queries\n",
      "Got 604 results\n",
      "Posting 600 queries\n",
      "Got 584 results\n",
      "Posting 600 queries\n",
      "Got 584 results\n",
      "Posting 600 queries\n",
      "Got 570 results\n",
      "Posting 600 queries\n",
      "Got 578 results\n",
      "Posting 600 queries\n",
      "Got 589 results\n",
      "Posting 600 queries\n",
      "Got 591 results\n",
      "Posting 600 queries\n",
      "Got 576 results\n",
      "Posting 600 queries\n",
      "Got 605 results\n",
      "Posting 600 queries\n",
      "Got 592 results\n",
      "Posting 600 queries\n",
      "Got 575 results\n",
      "Posting 600 queries\n",
      "Got 594 results\n",
      "Posting 600 queries\n",
      "Got 594 results\n",
      "Posting 600 queries\n",
      "Got 592 results\n",
      "Posting 600 queries\n",
      "Got 596 results\n",
      "Posting 600 queries\n",
      "Got 586 results\n",
      "Posting 600 queries\n",
      "Got 583 results\n",
      "Posting 600 queries\n",
      "Got 590 results\n",
      "Posting 600 queries\n",
      "Got 585 results\n",
      "Posting 600 queries\n",
      "Got 575 results\n",
      "Posting 600 queries\n",
      "Got 602 results\n",
      "Posting 600 queries\n",
      "Got 595 results\n",
      "Posting 600 queries\n",
      "Got 599 results\n",
      "Posting 600 queries\n",
      "Got 595 results\n",
      "Posting 600 queries\n",
      "Got 590 results\n",
      "Posting 600 queries\n",
      "Got 578 results\n",
      "Posting 600 queries\n",
      "Got 587 results\n",
      "Posting 600 queries\n",
      "Got 593 results\n",
      "Posting 600 queries\n",
      "Got 580 results\n",
      "Posting 600 queries\n",
      "Got 565 results\n",
      "Posting 600 queries\n",
      "Got 573 results\n",
      "Posting 600 queries\n",
      "Got 594 results\n",
      "Posting 600 queries\n",
      "Got 587 results\n",
      "Posting 600 queries\n",
      "Got 584 results\n",
      "Posting 600 queries\n",
      "Got 595 results\n",
      "Posting 600 queries\n",
      "Got 593 results\n",
      "Posting 600 queries\n",
      "Got 604 results\n",
      "Posting 600 queries\n",
      "Got 583 results\n",
      "Posting 600 queries\n",
      "Got 566 results\n",
      "Posting 600 queries\n",
      "Got 576 results\n",
      "Posting 600 queries\n",
      "Got 588 results\n",
      "Posting 600 queries\n",
      "Got 584 results\n",
      "Posting 600 queries\n",
      "Got 585 results\n",
      "Posting 600 queries\n",
      "Got 598 results\n",
      "Posting 600 queries\n",
      "Got 600 results\n",
      "Posting 600 queries\n",
      "Got 566 results\n",
      "Posting 600 queries\n",
      "Got 587 results\n",
      "Posting 600 queries\n",
      "Got 582 results\n",
      "Posting 600 queries\n",
      "Got 597 results\n",
      "Posting 600 queries\n",
      "Got 569 results\n",
      "Posting 600 queries\n",
      "Got 610 results\n",
      "Posting 600 queries\n",
      "Got 599 results\n",
      "Posting 600 queries\n",
      "Got 571 results\n",
      "Posting 600 queries\n",
      "Got 587 results\n",
      "Posting 600 queries\n",
      "Got 585 results\n",
      "Posting 600 queries\n",
      "Got 591 results\n",
      "Posting 600 queries\n",
      "Got 579 results\n",
      "Posting 600 queries\n",
      "Got 563 results\n",
      "Posting 600 queries\n",
      "Got 574 results\n",
      "Posting 600 queries\n",
      "Got 572 results\n",
      "Posting 600 queries\n",
      "Got 587 results\n",
      "Posting 600 queries\n",
      "Got 583 results\n",
      "Posting 600 queries\n",
      "Got 580 results\n",
      "Posting 600 queries\n",
      "Got 571 results\n",
      "Posting 600 queries\n",
      "Got 590 results\n",
      "Posting 600 queries\n",
      "Got 590 results\n",
      "Posting 600 queries\n",
      "Got 590 results\n",
      "Posting 600 queries\n",
      "Got 569 results\n",
      "Posting 600 queries\n",
      "Got 577 results\n",
      "Posting 600 queries\n",
      "Got 574 results\n",
      "Posting 600 queries\n",
      "Got 590 results\n",
      "Posting 600 queries\n",
      "Got 585 results\n",
      "Posting 600 queries\n",
      "Got 580 results\n",
      "Posting 600 queries\n",
      "Got 566 results\n",
      "Posting 600 queries\n",
      "Got 580 results\n",
      "Posting 600 queries\n",
      "Got 591 results\n",
      "Posting 600 queries\n",
      "Got 571 results\n",
      "Posting 600 queries\n",
      "Got 575 results\n",
      "Posting 600 queries\n",
      "Got 580 results\n",
      "Posting 600 queries\n",
      "Got 578 results\n",
      "Posting 600 queries\n",
      "Got 585 results\n",
      "Posting 600 queries\n",
      "Got 601 results\n",
      "Posting 600 queries\n",
      "Got 572 results\n",
      "Posting 600 queries\n",
      "Got 587 results\n",
      "Posting 600 queries\n",
      "Got 589 results\n",
      "Posting 600 queries\n",
      "Got 581 results\n",
      "Posting 600 queries\n",
      "Got 580 results\n",
      "Posting 600 queries\n",
      "Got 583 results\n",
      "Posting 600 queries\n",
      "Got 583 results\n",
      "Posting 600 queries\n",
      "Got 577 results\n",
      "Posting 600 queries\n",
      "Got 582 results\n",
      "Posting 600 queries\n",
      "Got 574 results\n",
      "Posting 600 queries\n",
      "Got 597 results\n",
      "Posting 600 queries\n",
      "Got 571 results\n",
      "Posting 600 queries\n",
      "Got 581 results\n",
      "Posting 600 queries\n",
      "Got 595 results\n",
      "Posting 600 queries\n",
      "Got 574 results\n",
      "Posting 600 queries\n",
      "Got 592 results\n",
      "Posting 600 queries\n",
      "Got 581 results\n",
      "Posting 600 queries\n",
      "Got 555 results\n",
      "Posting 600 queries\n",
      "Got 576 results\n",
      "Posting 600 queries\n",
      "Got 579 results\n",
      "Posting 600 queries\n",
      "Got 579 results\n",
      "Posting 600 queries\n",
      "Got 590 results\n",
      "Posting 600 queries\n",
      "Got 569 results\n",
      "Posting 600 queries\n",
      "Got 572 results\n",
      "Posting 600 queries\n",
      "Got 565 results\n",
      "Posting 600 queries\n",
      "Got 576 results\n",
      "Posting 600 queries\n",
      "Got 578 results\n",
      "Posting 600 queries\n",
      "Got 582 results\n",
      "Posting 600 queries\n",
      "Got 586 results\n",
      "Posting 600 queries\n",
      "Got 567 results\n",
      "Posting 600 queries\n",
      "Got 584 results\n",
      "Posting 600 queries\n",
      "Got 575 results\n",
      "Posting 600 queries\n",
      "Got 575 results\n",
      "Posting 600 queries\n",
      "Got 593 results\n",
      "Posting 600 queries\n",
      "Got 592 results\n",
      "Posting 600 queries\n",
      "Got 584 results\n",
      "Posting 600 queries\n",
      "Got 589 results\n",
      "Posting 600 queries\n",
      "Got 581 results\n",
      "Posting 600 queries\n",
      "Got 576 results\n",
      "Posting 600 queries\n",
      "Got 577 results\n",
      "Posting 600 queries\n",
      "Got 563 results\n",
      "Posting 600 queries\n",
      "Got 564 results\n",
      "Posting 600 queries\n",
      "Got 585 results\n",
      "Posting 600 queries\n",
      "Got 580 results\n",
      "Posting 600 queries\n",
      "Got 573 results\n",
      "Posting 600 queries\n",
      "Got 574 results\n",
      "Posting 600 queries\n",
      "Got 570 results\n",
      "Posting 600 queries\n",
      "Got 579 results\n",
      "Posting 600 queries\n",
      "Got 590 results\n",
      "Posting 600 queries\n",
      "Got 588 results\n",
      "Posting 600 queries\n",
      "Got 591 results\n",
      "Posting 600 queries\n",
      "Got 577 results\n",
      "Posting 600 queries\n",
      "Got 582 results\n",
      "Posting 600 queries\n",
      "Got 583 results\n",
      "Posting 600 queries\n",
      "Got 571 results\n",
      "Posting 600 queries\n",
      "Got 580 results\n",
      "Posting 600 queries\n",
      "Got 566 results\n",
      "Posting 600 queries\n",
      "Got 574 results\n",
      "Posting 600 queries\n",
      "Got 588 results\n",
      "Posting 600 queries\n",
      "Got 580 results\n",
      "Posting 600 queries\n",
      "Got 580 results\n",
      "Posting 600 queries\n",
      "Got 566 results\n",
      "Posting 600 queries\n",
      "Got 578 results\n",
      "Posting 600 queries\n",
      "Got 570 results\n",
      "Posting 600 queries\n",
      "Got 569 results\n",
      "Posting 600 queries\n",
      "Got 589 results\n",
      "Posting 600 queries\n",
      "Got 584 results\n",
      "Posting 600 queries\n",
      "Got 586 results\n",
      "Posting 600 queries\n",
      "Got 583 results\n",
      "Posting 600 queries\n",
      "Got 620 results\n",
      "Posting 600 queries\n",
      "Got 594 results\n",
      "Posting 600 queries\n",
      "Got 604 results\n",
      "Posting 600 queries\n",
      "Got 577 results\n",
      "Posting 600 queries\n",
      "Got 580 results\n",
      "Posting 600 queries\n",
      "Got 577 results\n",
      "Posting 600 queries\n",
      "Got 595 results\n",
      "Posting 600 queries\n",
      "Got 578 results\n",
      "Posting 600 queries\n",
      "Got 580 results\n",
      "Posting 600 queries\n",
      "Got 571 results\n",
      "Posting 600 queries\n",
      "Got 582 results\n",
      "Posting 600 queries\n",
      "Got 573 results\n",
      "Posting 600 queries\n",
      "Got 576 results\n",
      "Posting 600 queries\n",
      "Got 560 results\n",
      "Posting 600 queries\n",
      "Got 576 results\n",
      "Posting 600 queries\n",
      "Got 584 results\n",
      "Posting 600 queries\n",
      "Got 577 results\n",
      "Posting 600 queries\n",
      "Got 571 results\n",
      "Posting 600 queries\n",
      "Got 580 results\n",
      "Posting 600 queries\n",
      "Got 572 results\n",
      "Posting 600 queries\n",
      "Got 572 results\n",
      "Posting 600 queries\n",
      "Got 572 results\n",
      "Posting 600 queries\n",
      "Got 573 results\n",
      "Posting 600 queries\n",
      "Got 572 results\n",
      "Posting 600 queries\n",
      "Got 577 results\n",
      "Posting 600 queries\n",
      "Got 571 results\n",
      "Posting 600 queries\n",
      "Got 573 results\n",
      "Posting 600 queries\n",
      "Got 576 results\n",
      "Posting 600 queries\n",
      "Got 571 results\n",
      "Posting 600 queries\n",
      "Got 581 results\n",
      "Posting 600 queries\n",
      "Got 576 results\n",
      "Posting 600 queries\n",
      "Got 568 results\n",
      "Posting 600 queries\n",
      "Got 571 results\n",
      "Posting 600 queries\n",
      "Got 577 results\n",
      "Posting 600 queries\n",
      "Got 587 results\n",
      "Posting 600 queries\n",
      "Got 590 results\n",
      "Posting 600 queries\n",
      "Got 587 results\n",
      "Posting 600 queries\n",
      "Got 583 results\n",
      "Posting 600 queries\n",
      "Got 591 results\n",
      "Posting 600 queries\n",
      "Got 578 results\n",
      "Posting 600 queries\n",
      "Got 583 results\n",
      "Posting 600 queries\n",
      "Got 591 results\n",
      "Posting 600 queries\n",
      "Got 326 results\n",
      "Posting 600 queries\n",
      "Got 96 results\n",
      "Posting 527 queries\n",
      "Got 147 results\n",
      "Made 281 calls\n",
      "Got 154948 matches from 168527 queries, of which 91053 contained both institutes and citation information\n"
     ]
    }
   ],
   "source": [
    "# df_arxiv = pd.read_json(\"data/cs_arxiv.json\", orient=\"records\")\n",
    "# raw_titles = [(row.id, row.raw_title) for _, row in df_arxiv.iterrows()]\n",
    "\n",
    "optional_columns = dict(language=\"L\", full_title=\"E.DN\",\n",
    "                        conference=\"CN\", journal=\"E.BV\", doi=\"E.DOI\")\n",
    "\n",
    "data = mak_from_titles(raw_titles, call_limit=300, optional_columns=optional_columns)\n",
    "df_magapi = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_magapi.to_json(\"data/magapi_arxiv_match.json\", orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "168527"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_magapi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arxiv_sources</th>\n",
       "      <th>citations</th>\n",
       "      <th>date</th>\n",
       "      <th>doi</th>\n",
       "      <th>full_title</th>\n",
       "      <th>institutes</th>\n",
       "      <th>journal</th>\n",
       "      <th>language</th>\n",
       "      <th>matched</th>\n",
       "      <th>pid</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[https://arxiv.org/abs/0704.0002]</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2009-05-01</td>\n",
       "      <td>10.1007/s00373-008-0834-4</td>\n",
       "      <td>Sparsity-certifying Graph Decompositions</td>\n",
       "      <td>[smith college, university of massachusetts am...</td>\n",
       "      <td>Graphs and Combinatorics</td>\n",
       "      <td>en</td>\n",
       "      <td>True</td>\n",
       "      <td>oai:arXiv.org:0704.0002</td>\n",
       "      <td>sparsity certifying graph decompositions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>oai:arXiv.org:0704.0046</td>\n",
       "      <td>a limit relation for entropy and channel capac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[https://arxiv.org/abs/0704.0047]</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2003-02-01</td>\n",
       "      <td>10.1108/00022660310457248</td>\n",
       "      <td>Intelligent location of simultaneously active ...</td>\n",
       "      <td>[university of ljubljana]</td>\n",
       "      <td>Aircraft Engineering and Aerospace Technology</td>\n",
       "      <td>en</td>\n",
       "      <td>True</td>\n",
       "      <td>oai:arXiv.org:0704.0047</td>\n",
       "      <td>intelligent location of simultaneously active ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2007-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Intelligent location of simultaneously active ...</td>\n",
       "      <td>[university of ljubljana]</td>\n",
       "      <td>arXiv preprint arXiv:0704.0050</td>\n",
       "      <td>en</td>\n",
       "      <td>True</td>\n",
       "      <td>oai:arXiv.org:0704.0050</td>\n",
       "      <td>intelligent location of simultaneously active ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>oai:arXiv.org:0704.0062</td>\n",
       "      <td>on line viterbi algorithm and its relationship...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       arxiv_sources  citations        date  \\\n",
       "0  [https://arxiv.org/abs/0704.0002]       17.0  2009-05-01   \n",
       "1                                NaN        NaN         NaN   \n",
       "2  [https://arxiv.org/abs/0704.0047]        8.0  2003-02-01   \n",
       "3                                 []        0.0  2007-01-01   \n",
       "4                                NaN        NaN         NaN   \n",
       "\n",
       "                         doi  \\\n",
       "0  10.1007/s00373-008-0834-4   \n",
       "1                        NaN   \n",
       "2  10.1108/00022660310457248   \n",
       "3                        NaN   \n",
       "4                        NaN   \n",
       "\n",
       "                                          full_title  \\\n",
       "0           Sparsity-certifying Graph Decompositions   \n",
       "1                                                NaN   \n",
       "2  Intelligent location of simultaneously active ...   \n",
       "3  Intelligent location of simultaneously active ...   \n",
       "4                                                NaN   \n",
       "\n",
       "                                          institutes  \\\n",
       "0  [smith college, university of massachusetts am...   \n",
       "1                                                NaN   \n",
       "2                          [university of ljubljana]   \n",
       "3                          [university of ljubljana]   \n",
       "4                                                NaN   \n",
       "\n",
       "                                         journal language  matched  \\\n",
       "0                       Graphs and Combinatorics       en     True   \n",
       "1                                            NaN      NaN    False   \n",
       "2  Aircraft Engineering and Aerospace Technology       en     True   \n",
       "3                 arXiv preprint arXiv:0704.0050       en     True   \n",
       "4                                            NaN      NaN    False   \n",
       "\n",
       "                       pid                                              title  \n",
       "0  oai:arXiv.org:0704.0002           sparsity certifying graph decompositions  \n",
       "1  oai:arXiv.org:0704.0046  a limit relation for entropy and channel capac...  \n",
       "2  oai:arXiv.org:0704.0047  intelligent location of simultaneously active ...  \n",
       "3  oai:arXiv.org:0704.0050  intelligent location of simultaneously active ...  \n",
       "4  oai:arXiv.org:0704.0062  on line viterbi algorithm and its relationship...  "
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_magapi.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2a: Match MAG API to MAG DB on DOI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open a DB connections\n",
    "with open('/Users/jklinger/Nesta-AWS/AWS-RDS-config/open-academic-graph.config') as f:\n",
    "        host, port, _, user, password = f.read().split(':')\n",
    "database_uri = 'postgresql://{}:{}@{}/{}'.format(user, password, host, \"microsoft_academic_graph\")\n",
    "con = create_engine(database_uri)\n",
    "\n",
    "# \n",
    "query = '''select paper from microsoft_academic_graph where ((((paper ->> 'doi'::text))::character varying(255))) in :values;'''\n",
    "dois = df_magapi.loc[~pd.isnull(df_magapi.doi),\"doi\"]\n",
    "\n",
    "papers = execute_IN_in_chunks(con, query, dois, 500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>oag_abstract</th>\n",
       "      <th>oag_authors</th>\n",
       "      <th>oag_doc_type</th>\n",
       "      <th>oag_doi</th>\n",
       "      <th>oag_fos</th>\n",
       "      <th>oag_id</th>\n",
       "      <th>oag_issue</th>\n",
       "      <th>oag_keywords</th>\n",
       "      <th>oag_lang</th>\n",
       "      <th>oag_n_citation</th>\n",
       "      <th>oag_page_end</th>\n",
       "      <th>oag_page_start</th>\n",
       "      <th>oag_publisher</th>\n",
       "      <th>oag_references</th>\n",
       "      <th>oag_title</th>\n",
       "      <th>oag_url</th>\n",
       "      <th>oag_venue</th>\n",
       "      <th>oag_volume</th>\n",
       "      <th>oag_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In most discussions about information and know...</td>\n",
       "      <td>[{'org': 'GRDS-EBSI, Université de Montréal, C...</td>\n",
       "      <td>Journal</td>\n",
       "      <td>10.1002/asi.v60:9</td>\n",
       "      <td>[Natural language processing, Design, Social s...</td>\n",
       "      <td>f65c2f5a-648f-4dcc-a974-f841a7d59f4b</td>\n",
       "      <td>9</td>\n",
       "      <td>[lenguaje natural, langage naturel, conception...</td>\n",
       "      <td>en</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1906</td>\n",
       "      <td>1895</td>\n",
       "      <td>Wiley Subscription Services, Inc., A Wiley Com...</td>\n",
       "      <td>[01671f95-823d-41d3-96e0-78d17875260d, 02601ff...</td>\n",
       "      <td>Intertextual semantics: A semantics for inform...</td>\n",
       "      <td>[http://onlinelibrary.wiley.com/doi/10.1002/as...</td>\n",
       "      <td>Journal of the Association for Information Sci...</td>\n",
       "      <td>60</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Many algorithms have been implemented for the ...</td>\n",
       "      <td>[{'org': 'Arab Academy for Banking and Financi...</td>\n",
       "      <td>Journal</td>\n",
       "      <td>10.1002/asi.v60:9</td>\n",
       "      <td>[Natural language processing, Speech recogniti...</td>\n",
       "      <td>efc8ba6d-0902-4492-8925-4c852235574d</td>\n",
       "      <td>9</td>\n",
       "      <td>[search result, rocchio and naive bayes, estud...</td>\n",
       "      <td>en</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1844</td>\n",
       "      <td>1836</td>\n",
       "      <td>Wiley Subscription Services, Inc., A Wiley Com...</td>\n",
       "      <td>[01e036ec-11c7-4251-98cc-13d11b59d0f0, 2082b5a...</td>\n",
       "      <td>A comparison of text-classification techniques...</td>\n",
       "      <td>[http://onlinelibrary.wiley.com/doi/10.1002/as...</td>\n",
       "      <td>Journal of the Association for Information Sci...</td>\n",
       "      <td>60</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'org': 'Royal School of Library and Informat...</td>\n",
       "      <td>Journal</td>\n",
       "      <td>10.1002/asi.v60:9</td>\n",
       "      <td>[Computer Science, Interactive media, Informat...</td>\n",
       "      <td>d2b585ff-07b7-4a44-a184-872f91906fa4</td>\n",
       "      <td>9</td>\n",
       "      <td>[interactive information retrieval]</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1945</td>\n",
       "      <td>1944</td>\n",
       "      <td>Wiley Subscription Services, Inc., A Wiley Com...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Interactive Information Retrieval in Digital E...</td>\n",
       "      <td>[http://onlinelibrary.wiley.com/doi/10.1002/as...</td>\n",
       "      <td>Journal of the Association for Information Sci...</td>\n",
       "      <td>60</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'org': '435 East 70th Street, Apartment 30D,...</td>\n",
       "      <td>Journal</td>\n",
       "      <td>10.1002/asi.v60:9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>c89cd70c-9336-4b78-b3de-eb3b26d33c1c</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1942</td>\n",
       "      <td>1942</td>\n",
       "      <td>Wiley Subscription Services, Inc., A Wiley Com...</td>\n",
       "      <td>[14d853c3-57d7-4163-ba84-f9e8fa911a38, 50429db...</td>\n",
       "      <td>Design: The vision and the plans: Additional r...</td>\n",
       "      <td>[http://dl.acm.org/citation.cfm?id=1598912, ht...</td>\n",
       "      <td>Journal of the Association for Information Sci...</td>\n",
       "      <td>60</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The universe of information has been enriched ...</td>\n",
       "      <td>[{'org': 'Department of Information Science, B...</td>\n",
       "      <td>Journal</td>\n",
       "      <td>10.1002/asi.v60:9</td>\n",
       "      <td>[Method, Web query classification, Computer Sc...</td>\n",
       "      <td>b4dcacf4-265c-47ef-ba2f-57e8d027c3cd</td>\n",
       "      <td>9</td>\n",
       "      <td>[dynamic change, infometrie, web evolve 2008, ...</td>\n",
       "      <td>en</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1740</td>\n",
       "      <td>1730</td>\n",
       "      <td>Wiley Subscription Services, Inc., A Wiley Com...</td>\n",
       "      <td>[06a3f364-4630-402c-8ed7-7f0ede34ff1a, 0b489d9...</td>\n",
       "      <td>A method for measuring the evolution of a topi...</td>\n",
       "      <td>[http://journal.webscience.org/32/1/WebEvolve2...</td>\n",
       "      <td>Journal of the Association for Information Sci...</td>\n",
       "      <td>60</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        oag_abstract  \\\n",
       "0  In most discussions about information and know...   \n",
       "1  Many algorithms have been implemented for the ...   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4  The universe of information has been enriched ...   \n",
       "\n",
       "                                         oag_authors oag_doc_type  \\\n",
       "0  [{'org': 'GRDS-EBSI, Université de Montréal, C...      Journal   \n",
       "1  [{'org': 'Arab Academy for Banking and Financi...      Journal   \n",
       "2  [{'org': 'Royal School of Library and Informat...      Journal   \n",
       "3  [{'org': '435 East 70th Street, Apartment 30D,...      Journal   \n",
       "4  [{'org': 'Department of Information Science, B...      Journal   \n",
       "\n",
       "             oag_doi                                            oag_fos  \\\n",
       "0  10.1002/asi.v60:9  [Natural language processing, Design, Social s...   \n",
       "1  10.1002/asi.v60:9  [Natural language processing, Speech recogniti...   \n",
       "2  10.1002/asi.v60:9  [Computer Science, Interactive media, Informat...   \n",
       "3  10.1002/asi.v60:9                                                NaN   \n",
       "4  10.1002/asi.v60:9  [Method, Web query classification, Computer Sc...   \n",
       "\n",
       "                                 oag_id oag_issue  \\\n",
       "0  f65c2f5a-648f-4dcc-a974-f841a7d59f4b         9   \n",
       "1  efc8ba6d-0902-4492-8925-4c852235574d         9   \n",
       "2  d2b585ff-07b7-4a44-a184-872f91906fa4         9   \n",
       "3  c89cd70c-9336-4b78-b3de-eb3b26d33c1c         9   \n",
       "4  b4dcacf4-265c-47ef-ba2f-57e8d027c3cd         9   \n",
       "\n",
       "                                        oag_keywords oag_lang  oag_n_citation  \\\n",
       "0  [lenguaje natural, langage naturel, conception...       en            50.0   \n",
       "1  [search result, rocchio and naive bayes, estud...       en            50.0   \n",
       "2                [interactive information retrieval]       en             NaN   \n",
       "3                                                NaN       en            50.0   \n",
       "4  [dynamic change, infometrie, web evolve 2008, ...       en            50.0   \n",
       "\n",
       "  oag_page_end oag_page_start  \\\n",
       "0         1906           1895   \n",
       "1         1844           1836   \n",
       "2         1945           1944   \n",
       "3         1942           1942   \n",
       "4         1740           1730   \n",
       "\n",
       "                                       oag_publisher  \\\n",
       "0  Wiley Subscription Services, Inc., A Wiley Com...   \n",
       "1  Wiley Subscription Services, Inc., A Wiley Com...   \n",
       "2  Wiley Subscription Services, Inc., A Wiley Com...   \n",
       "3  Wiley Subscription Services, Inc., A Wiley Com...   \n",
       "4  Wiley Subscription Services, Inc., A Wiley Com...   \n",
       "\n",
       "                                      oag_references  \\\n",
       "0  [01671f95-823d-41d3-96e0-78d17875260d, 02601ff...   \n",
       "1  [01e036ec-11c7-4251-98cc-13d11b59d0f0, 2082b5a...   \n",
       "2                                                NaN   \n",
       "3  [14d853c3-57d7-4163-ba84-f9e8fa911a38, 50429db...   \n",
       "4  [06a3f364-4630-402c-8ed7-7f0ede34ff1a, 0b489d9...   \n",
       "\n",
       "                                           oag_title  \\\n",
       "0  Intertextual semantics: A semantics for inform...   \n",
       "1  A comparison of text-classification techniques...   \n",
       "2  Interactive Information Retrieval in Digital E...   \n",
       "3  Design: The vision and the plans: Additional r...   \n",
       "4  A method for measuring the evolution of a topi...   \n",
       "\n",
       "                                             oag_url  \\\n",
       "0  [http://onlinelibrary.wiley.com/doi/10.1002/as...   \n",
       "1  [http://onlinelibrary.wiley.com/doi/10.1002/as...   \n",
       "2  [http://onlinelibrary.wiley.com/doi/10.1002/as...   \n",
       "3  [http://dl.acm.org/citation.cfm?id=1598912, ht...   \n",
       "4  [http://journal.webscience.org/32/1/WebEvolve2...   \n",
       "\n",
       "                                           oag_venue oag_volume  oag_year  \n",
       "0  Journal of the Association for Information Sci...         60      2009  \n",
       "1  Journal of the Association for Information Sci...         60      2009  \n",
       "2  Journal of the Association for Information Sci...         60      2009  \n",
       "3  Journal of the Association for Information Sci...         60      2009  \n",
       "4  Journal of the Association for Information Sci...         60      2009  "
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_papers = pd.DataFrame([p[0] for p in papers]).add_prefix('oag_')\n",
    "df_papers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63964, 59948, 59948)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_papers), len(set(df_papers.oag_doi)), len(df_papers.drop_duplicates(subset=\"oag_doi\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Join it all together and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "_df = df_papers.drop_duplicates(subset=\"oag_doi\")\n",
    "condition = ~pd.isnull(df_magapi.doi)\n",
    "df_magapi_magdb = _df.join(df_magapi.loc[condition].set_index(\"doi\").add_prefix(\"mag_\"), on=\"oag_doi\")\n",
    "df_magapi_magdb.rename(columns = {'mag_pid': 'arxiv_id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>oag_abstract</th>\n",
       "      <th>oag_authors</th>\n",
       "      <th>oag_doc_type</th>\n",
       "      <th>oag_doi</th>\n",
       "      <th>oag_fos</th>\n",
       "      <th>oag_id</th>\n",
       "      <th>oag_issue</th>\n",
       "      <th>oag_keywords</th>\n",
       "      <th>oag_lang</th>\n",
       "      <th>oag_n_citation</th>\n",
       "      <th>...</th>\n",
       "      <th>mag_arxiv_sources</th>\n",
       "      <th>mag_citations</th>\n",
       "      <th>mag_date</th>\n",
       "      <th>mag_full_title</th>\n",
       "      <th>mag_institutes</th>\n",
       "      <th>mag_journal</th>\n",
       "      <th>mag_language</th>\n",
       "      <th>mag_matched</th>\n",
       "      <th>arxiv_id</th>\n",
       "      <th>mag_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In most discussions about information and know...</td>\n",
       "      <td>[{'org': 'GRDS-EBSI, Université de Montréal, C...</td>\n",
       "      <td>Journal</td>\n",
       "      <td>10.1002/asi.v60:9</td>\n",
       "      <td>[Natural language processing, Design, Social s...</td>\n",
       "      <td>f65c2f5a-648f-4dcc-a974-f841a7d59f4b</td>\n",
       "      <td>9</td>\n",
       "      <td>[lenguaje natural, langage naturel, conception...</td>\n",
       "      <td>en</td>\n",
       "      <td>50.0</td>\n",
       "      <td>...</td>\n",
       "      <td>[https://arxiv.org/abs/0812.4332?context=cs]</td>\n",
       "      <td>161.0</td>\n",
       "      <td>2009-09-01</td>\n",
       "      <td>Content-based and algorithmic classifications ...</td>\n",
       "      <td>[university of amsterdam, university of sussex]</td>\n",
       "      <td>Journal of the Association for Information Sci...</td>\n",
       "      <td>en</td>\n",
       "      <td>True</td>\n",
       "      <td>oai:arXiv.org:0812.4332</td>\n",
       "      <td>content based and algorithmic classifications ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>In this paper we investigate the effects of te...</td>\n",
       "      <td>[{'org': 'Department of Finance, The Chinese U...</td>\n",
       "      <td>Journal</td>\n",
       "      <td>10.1002/asmb.v25:3</td>\n",
       "      <td>[Financial economics, Econometrics, Characteri...</td>\n",
       "      <td>ed6b3532-1de5-40a4-b811-5f05d9e618c3</td>\n",
       "      <td>3</td>\n",
       "      <td>[high order moments, markov switching, mixing ...</td>\n",
       "      <td>en@@@zh_cht</td>\n",
       "      <td>50.0</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2009-05-01</td>\n",
       "      <td>Assessment and propagation of input uncertaint...</td>\n",
       "      <td>[instituto de estudios superiores de administr...</td>\n",
       "      <td>Applied Stochastic Models in Business and Indu...</td>\n",
       "      <td>en</td>\n",
       "      <td>True</td>\n",
       "      <td>oai:arXiv.org:0704.1768</td>\n",
       "      <td>assessment and propagation of input uncertaint...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Map the vertices of a graph to (not necessaril...</td>\n",
       "      <td>[{'org': '(Chargée de Recherches du F.R.S.—FNR...</td>\n",
       "      <td>Journal</td>\n",
       "      <td>10.1002/jgt.20554</td>\n",
       "      <td>[Graph power, Petersen graph, Unit disk graph,...</td>\n",
       "      <td>d1c359e7-bcb1-4433-b77b-a3e393eec667</td>\n",
       "      <td>3</td>\n",
       "      <td>[packing non overlapping unit discs, circular ...</td>\n",
       "      <td>en</td>\n",
       "      <td>50.0</td>\n",
       "      <td>...</td>\n",
       "      <td>[https://arxiv.org/abs/0812.4346?context=cs]</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2011-11-01</td>\n",
       "      <td>The plane-width of graphs</td>\n",
       "      <td>[university of toronto, university of primorsk...</td>\n",
       "      <td>Journal of Graph Theory</td>\n",
       "      <td>en@@@fr</td>\n",
       "      <td>True</td>\n",
       "      <td>oai:arXiv.org:0812.4346</td>\n",
       "      <td>the plane width of graphs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>A new notion of partition-determined functions...</td>\n",
       "      <td>[{'org': 'Department of Statistics, Yale Unive...</td>\n",
       "      <td>Journal</td>\n",
       "      <td>10.1002/rsa.20385</td>\n",
       "      <td>[Combinatorics, Number theory, Discrete mathem...</td>\n",
       "      <td>f78e174e-8566-451d-8113-7ee891750c18</td>\n",
       "      <td>4</td>\n",
       "      <td>[cardinality inequalities, entropy inequalitie...</td>\n",
       "      <td>en</td>\n",
       "      <td>50.0</td>\n",
       "      <td>...</td>\n",
       "      <td>[https://arxiv.org/abs/0901.0055?context=cs]</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2012-07-01</td>\n",
       "      <td>Entropy and set cardinality inequalities for p...</td>\n",
       "      <td>[yale university, georgia institute of technol...</td>\n",
       "      <td>Random Structures and Algorithms</td>\n",
       "      <td>en</td>\n",
       "      <td>True</td>\n",
       "      <td>oai:arXiv.org:0901.0055</td>\n",
       "      <td>entropy and set cardinality inequalities for p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Abstract#R##N##R##N#Biometrics make human iden...</td>\n",
       "      <td>[{'org': 'Sagem Sécurité, Osny, France', 'name...</td>\n",
       "      <td>Journal</td>\n",
       "      <td>10.1002/sec.206</td>\n",
       "      <td>[Identification, Computer Science, Bloom filte...</td>\n",
       "      <td>6b66e31d-a3ba-4075-a16a-cc9f500bb2f0</td>\n",
       "      <td>5</td>\n",
       "      <td>[locality sensitive hashing, bloom filter, bio...</td>\n",
       "      <td>en</td>\n",
       "      <td>50.0</td>\n",
       "      <td>...</td>\n",
       "      <td>[https://arxiv.org/abs/0901.1062?context=cs]</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2011-01-05</td>\n",
       "      <td>Identification with encrypted biometric data</td>\n",
       "      <td>[sagem]</td>\n",
       "      <td>Security and Communication Networks</td>\n",
       "      <td>en</td>\n",
       "      <td>True</td>\n",
       "      <td>oai:arXiv.org:0901.1062</td>\n",
       "      <td>identification with encrypted biometric data</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         oag_abstract  \\\n",
       "0   In most discussions about information and know...   \n",
       "28  In this paper we investigate the effects of te...   \n",
       "38  Map the vertices of a graph to (not necessaril...   \n",
       "39  A new notion of partition-determined functions...   \n",
       "40  Abstract#R##N##R##N#Biometrics make human iden...   \n",
       "\n",
       "                                          oag_authors oag_doc_type  \\\n",
       "0   [{'org': 'GRDS-EBSI, Université de Montréal, C...      Journal   \n",
       "28  [{'org': 'Department of Finance, The Chinese U...      Journal   \n",
       "38  [{'org': '(Chargée de Recherches du F.R.S.—FNR...      Journal   \n",
       "39  [{'org': 'Department of Statistics, Yale Unive...      Journal   \n",
       "40  [{'org': 'Sagem Sécurité, Osny, France', 'name...      Journal   \n",
       "\n",
       "               oag_doi                                            oag_fos  \\\n",
       "0    10.1002/asi.v60:9  [Natural language processing, Design, Social s...   \n",
       "28  10.1002/asmb.v25:3  [Financial economics, Econometrics, Characteri...   \n",
       "38   10.1002/jgt.20554  [Graph power, Petersen graph, Unit disk graph,...   \n",
       "39   10.1002/rsa.20385  [Combinatorics, Number theory, Discrete mathem...   \n",
       "40     10.1002/sec.206  [Identification, Computer Science, Bloom filte...   \n",
       "\n",
       "                                  oag_id oag_issue  \\\n",
       "0   f65c2f5a-648f-4dcc-a974-f841a7d59f4b         9   \n",
       "28  ed6b3532-1de5-40a4-b811-5f05d9e618c3         3   \n",
       "38  d1c359e7-bcb1-4433-b77b-a3e393eec667         3   \n",
       "39  f78e174e-8566-451d-8113-7ee891750c18         4   \n",
       "40  6b66e31d-a3ba-4075-a16a-cc9f500bb2f0         5   \n",
       "\n",
       "                                         oag_keywords     oag_lang  \\\n",
       "0   [lenguaje natural, langage naturel, conception...           en   \n",
       "28  [high order moments, markov switching, mixing ...  en@@@zh_cht   \n",
       "38  [packing non overlapping unit discs, circular ...           en   \n",
       "39  [cardinality inequalities, entropy inequalitie...           en   \n",
       "40  [locality sensitive hashing, bloom filter, bio...           en   \n",
       "\n",
       "    oag_n_citation                        ...                          \\\n",
       "0             50.0                        ...                           \n",
       "28            50.0                        ...                           \n",
       "38            50.0                        ...                           \n",
       "39            50.0                        ...                           \n",
       "40            50.0                        ...                           \n",
       "\n",
       "                               mag_arxiv_sources mag_citations    mag_date  \\\n",
       "0   [https://arxiv.org/abs/0812.4332?context=cs]         161.0  2009-09-01   \n",
       "28                                            []           0.0  2009-05-01   \n",
       "38  [https://arxiv.org/abs/0812.4346?context=cs]           4.0  2011-11-01   \n",
       "39  [https://arxiv.org/abs/0901.0055?context=cs]          24.0  2012-07-01   \n",
       "40  [https://arxiv.org/abs/0901.1062?context=cs]          28.0  2011-01-05   \n",
       "\n",
       "                                       mag_full_title  \\\n",
       "0   Content-based and algorithmic classifications ...   \n",
       "28  Assessment and propagation of input uncertaint...   \n",
       "38                          The plane-width of graphs   \n",
       "39  Entropy and set cardinality inequalities for p...   \n",
       "40       Identification with encrypted biometric data   \n",
       "\n",
       "                                       mag_institutes  \\\n",
       "0     [university of amsterdam, university of sussex]   \n",
       "28  [instituto de estudios superiores de administr...   \n",
       "38  [university of toronto, university of primorsk...   \n",
       "39  [yale university, georgia institute of technol...   \n",
       "40                                            [sagem]   \n",
       "\n",
       "                                          mag_journal mag_language  \\\n",
       "0   Journal of the Association for Information Sci...           en   \n",
       "28  Applied Stochastic Models in Business and Indu...           en   \n",
       "38                            Journal of Graph Theory      en@@@fr   \n",
       "39                   Random Structures and Algorithms           en   \n",
       "40                Security and Communication Networks           en   \n",
       "\n",
       "   mag_matched                 arxiv_id  \\\n",
       "0         True  oai:arXiv.org:0812.4332   \n",
       "28        True  oai:arXiv.org:0704.1768   \n",
       "38        True  oai:arXiv.org:0812.4346   \n",
       "39        True  oai:arXiv.org:0901.0055   \n",
       "40        True  oai:arXiv.org:0901.1062   \n",
       "\n",
       "                                            mag_title  \n",
       "0   content based and algorithmic classifications ...  \n",
       "28  assessment and propagation of input uncertaint...  \n",
       "38                          the plane width of graphs  \n",
       "39  entropy and set cardinality inequalities for p...  \n",
       "40       identification with encrypted biometric data  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_magapi_magdb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_magapi_magdb.to_json(\"data/magapi_oag_arxiv_match.json\", orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61701"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_magapi_magdb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
