{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import corex_topic as ct\n",
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from collections import Counter\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from gensim.corpora.dictionary import Dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read arXiv papers\n",
    "\n",
    "Note that these have already been collected via arXiv's OAI API, and text fields have been cleaned (lemmatized + nltk stopwords removed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = []\n",
    "# top_dir = \"data/\"\n",
    "# for file_name in os.listdir(top_dir):\n",
    "#     if not (file_name.startswith(\"arxiv\") and file_name.endswith(\".json\")):\n",
    "#         continue\n",
    "#     _df = pd.read_json(top_dir+file_name,orient=\"records\")\n",
    "#     _df.categories = _df.categories.apply(lambda x: x.split())\n",
    "#     condition = _df.categories.apply(lambda x : \"stat.ML\" in x) \n",
    "#     condition = condition | _df.categories.apply(lambda x : any(y.startswith(\"cs.\") for y in x))\n",
    "#     condition = condition & (_df.summary.apply(lambda s : len(s) > 20))\n",
    "#     new_df = _df.loc[condition].copy()\n",
    "#     data.append(new_df)\n",
    "#     del (_df)\n",
    "# df = pd.concat(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "168527"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#del data\n",
    "df = pd.read_json(\"data/cs_arxiv.json\", orient=\"records\")\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic modelling\n",
    "### Preprocessing: Generate a one-hot bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got vocab of size 10830\n"
     ]
    }
   ],
   "source": [
    "# Apply basic settings, including ngram generation\n",
    "count_vectoriser = CountVectorizer(binary=True, min_df=0.001, ngram_range=(1,3))\n",
    "count_vectoriser.fit(map(lambda x : \" \".join(x), df.summary))\n",
    "\n",
    "# Generate vocab mapping\n",
    "X = count_vectoriser.transform(map(lambda x : \" \".join(x), df.summary))\n",
    "vocab = {v:k for k,v in count_vectoriser.vocabulary_.items()}\n",
    "print(\"Got vocab of size\",len(vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic modelling using CorEx \n",
    "#### Finding the optimal number of topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36 23.286560655789977\n",
      "37 23.183222340984532\n",
      "38 23.580441233237128\n",
      "39 24.284446097361407\n"
     ]
    }
   ],
   "source": [
    "# Commented out since process is slow, see results below\n",
    "for i in np.arange(36,40,1):\n",
    "    topic_model = ct.Corex(n_hidden=i)\n",
    "    topic_model.fit(X)\n",
    "    print(i, topic_model.tc)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The above process is slow, so I post my results here:\n",
    "\n",
    "n_hidden corex\n",
    "10 18.620714071664917\n",
    "15 20.216069261814166\n",
    "20 21.309136910873598\n",
    "25 22.21641669549079\n",
    "30 22.921782501296075\n",
    "35 23.45382779752108\n",
    "36 23.286560655789977\n",
    "37 23.183222340984532\n",
    "38 23.580441233237128\n",
    "39 24.284446097361407\n",
    "40 24.661211053841633\n",
    "45 24.365936175220828\n",
    "50 24.595804637492318\n",
    "\n",
    "39 'appears to be' an inflection point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<corex_topic.Corex at 0x11a504550>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model = ct.Corex(n_hidden=39)\n",
    "topic_model.fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the topics, and generate topic weights for each arXiv paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: 'words' not provided to CorEx. Returning topics as lists of column indices\n"
     ]
    }
   ],
   "source": [
    "topics = topic_model.get_topics()\n",
    "# Build topic names\n",
    "topic_names = [\"_\".join(vocab[i] for i,_ in topic) for topic in topics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "channel_interference_transmission_wireless_receiver_rate_antenna_transmitter_mimo_transmit \n",
      "\n",
      "learning_neural_neural network_training_machine learning_classification_trained_machine_learn_learning algorithm \n",
      "\n",
      "image_recognition_feature_task_dataset_visual_text_segmentation_vision_semantic \n",
      "\n",
      "state art_art_state_deep_convolutional_convolutional neural_convolutional neural network_deep learning_datasets_deep neural \n",
      "\n",
      "service_security_mobile_device_traffic_technology_resource_attack_internet_management \n",
      "\n",
      "bound_upper_upper bound_np_polynomial time_constant_np hard_case_time algorithm_known \n",
      "\n",
      "algorithm_problem_optimization_optimization problem_solve_solution_solving_approximation_efficient_convergence \n",
      "\n",
      "graph_vertex_edge_undirected_directed_subgraph_shortest path_path_graph vertex_connected \n",
      "\n",
      "lower bound_code_lower_log_decoding_coding_length_omega_frac_log log \n",
      "\n",
      "research_year_ha_recent_human_community_attention_recent year_challenge_become \n",
      "\n",
      "dimensional_sparse_high dimensional_space_sparsity_low rank_vector_dimension_recovery_sample \n",
      "\n",
      "logic_quantum_semantics_automaton_calculus_theory_notion_formula_checking_reasoning \n",
      "\n",
      "software_development_implementation_tool_program_open source_interface_science_programming_execution \n",
      "\n",
      "numerical_probability_distribution_condition_numerical result_closed form_equation_markov_stochastic_sufficient condition \n",
      "\n",
      "node_communication_distributed_protocol_packet_allocation_link_routing_sensor network_topology \n",
      "\n",
      "performance_significantly_compared_estimation_better_result show_show_achieves_result_outperforms \n",
      "\n",
      "web_future_social medium_medium_project_business_twitter_organization_review_content \n",
      "\n",
      "proposed_proposed method_proposed algorithm_show proposed_proposed approach_performance proposed_effectiveness proposed_proposed scheme_algorithm proposed_result show proposed \n",
      "\n",
      "social_social network_role_play_robot_dynamic_interaction_decision making_decision_autonomous \n",
      "\n",
      "simulation_system_simulation result_control_energy_design_controller_simulation result show_sensor_efficiency \n",
      "\n",
      "propose_paper propose_large scale_scale_address_propose novel_propose new_large_demonstrate_effectiveness \n",
      "\n",
      "real_real world_world_widely_widely used_wide_wide range_application_synthetic_commonly used \n",
      "\n",
      "et_al_et al_polynomial_give_whether_proof_complete_every_theorem \n",
      "\n",
      "model_prediction_model based_proposed model_modeling_based model_predictive_model used_predict_graphical model \n",
      "\n",
      "data_data set_data structure_real data_data analysis_big data_data driven_data point_collected_synthetic data \n",
      "\n",
      "method_experimental_experimental result_method based_experimental result show_based method_new method_existing method_show method_method used \n",
      "\n",
      "optimal_convex_square_optimal solution_convex optimization_least square_non convex_sum_mean square_near optimal \n",
      "\n",
      "present_paper present_present new_present novel_also present_work present_present algorithm_present two_paper present novel_paper present new \n",
      "\n",
      "prove_class_game_general_player_also_hold_existence_theoretic_exists \n",
      "\n",
      "first_one_question_second_even_answer_main_two_contribution_may \n",
      "\n",
      "monte_carlo_monte carlo_random_degree_degree freedom_mutual information_freedom_message passing_mutual \n",
      "\n",
      "approach_based_technique_existing_framework_based approach_approach based_new approach_using_novel approach \n",
      "\n",
      "architecture_memory_parallel_network architecture_hardware_processor_cpu_computing_gpu_core \n",
      "\n",
      "user_account_insight_impact_analysis_provide_study_focus_issue_take account \n",
      "\n",
      "network_significant_layer_however_long_amount_end end_end_improvement_due \n",
      "\n",
      "linear_matrix_function_complexity_computational complexity_input_computational_non_linear time_non linear \n",
      "\n",
      "experiment_experiment show_extensive experiment_high quality_high_result indicate_quality_indicate_extensive_resolution \n",
      "\n",
      "different_two different_different type_three different_different approach_across different_many different_different level_using different_different way \n",
      "\n",
      "proposes_information_paper proposes_key_iii_ii_stage_two stage_secondly_firstly \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for t in topic_names:\n",
    "    print(t,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bag up the words and generate the topic weights\n",
    "topic_weights = defaultdict(list)\n",
    "df_corex = df.copy().add_prefix(\"arxiv_\")\n",
    "for t, _t in zip(topic_names, topics):\n",
    "    # Weight is given by the the sum of weights for the topic in this summary\n",
    "    for bow, (irow, row) in zip(X, df_corex.iterrows()):\n",
    "        total_weight = 0\n",
    "        for idx, weight in _t:\n",
    "            total_weight += bow[0, idx]*weight\n",
    "        topic_weights[t].append(total_weight)\n",
    "# Assign the weights to the DF\n",
    "for t, w in topic_weights.items():\n",
    "    df_corex[\"TOPIC_\"+t] = w\n",
    "df_corex.to_json(\"data/topics_corex.json\",orient=\"records\")\n",
    "del df_corex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic modelling using LDA \n",
    "#### Finding the optimal number of topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #corpus = [[(idx, 1) for idx in row.indices] for row in X]\n",
    "# gendict = Dictionary(df.summary.values)\n",
    "# corpus = [gendict.doc2bow(text) for text in df.summary.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## need to preprocess\n",
    "texts = []\n",
    "for row in X:\n",
    "    sentence = [vocab[w] for w in row.indices]\n",
    "    texts.append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gendict = Dictionary(texts)\n",
    "corpus = [gendict.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-af611a932bed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     lda_model = LdaMulticore(corpus, num_topics=n, id2word=gendict, \n\u001b[1;32m      3\u001b[0m                              iterations=100, chunksize=20000)\n\u001b[1;32m      4\u001b[0m     uci = CoherenceModel(model=lda_model, corpus=corpus,                                          \n\u001b[1;32m      5\u001b[0m                          texts=texts, coherence='c_uci')\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "for n in np.arange(20,50,5):\n",
    "    lda_model = LdaMulticore(corpus, num_topics=n, id2word=gendict, \n",
    "                             iterations=100, chunksize=20000)\n",
    "    uci = CoherenceModel(model=lda_model, corpus=corpus,                                          \n",
    "                         texts=texts, coherence='c_uci')\n",
    "    umass = CoherenceModel(model=lda_model, corpus=corpus, \n",
    "                           texts=texts, coherence='c_uci')    \n",
    "    print(n, uci.get_coherence(), umass.get_coherence(), lda_model.log_perplexity(corpus))\n",
    "    del lda_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 -4.969543411635572 -8.556184136224147\n",
      "100 -5.266592622573094 -8.01440828604216\n",
      "1000 -5.001288498955499 -8.038297273689187\n",
      "2500 -5.076360498203264 -8.039477225850383\n",
      "5000 -5.127604011808473 -8.018711878659518\n",
      "10000 -5.161609156027235 -8.043763480447423\n",
      "25000 -4.963276170377199 -8.01910197369833\n"
     ]
    }
   ],
   "source": [
    "for nit in [10, 100, 1000, 2500, 5000, 10000, 25000]:\n",
    "    lda_model = LdaMulticore(corpus, num_topics=28, id2word=gendict, \n",
    "                             iterations=nit, chunksize=20000)\n",
    "    coherence_model_lda = CoherenceModel(model=lda_model, corpus=corpus, \n",
    "                                         texts=texts, coherence='c_uci')    \n",
    "    print(nit, coherence_model_lda.get_coherence(), lda_model.log_perplexity(corpus))\n",
    "    del lda_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldamodel.log_perplexity(c_test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The above process is slow, so I post my results here:\n",
    "\n",
    "n_hidden UCI\n",
    "20 -0.07677146689828407\n",
    "21 -0.06265104443822114\n",
    "22 -0.06445968901965661\n",
    "23 -0.047409571995300916\n",
    "24 -0.0897110576799478\n",
    "25 -0.0634228910962744\n",
    "26 -0.005620293211399472\n",
    "27 -0.060972405381606636\n",
    "28 -0.0659826487685569\n",
    "29 -0.018131262824714105\n",
    "\n",
    "26 'appears to be' minimum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = LdaMulticore(corpus, num_topics=26, id2word=gendict, \n",
    "                         iterations=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_result_surface_simulation_numerical_using_study_two_dynamic_flow\n",
      "bound_algorithm_lower_random_log_number_probability_time_case_lower bound\n",
      "game_optimal_show_problem_strategy_result_player_study_algorithm_equilibrium\n",
      "ray_energy_wa_cosmic_matter_low_radiation_experiment_dark_section\n",
      "language_system_paper_model_theory_based_present_program_also_approach\n",
      "equation_field_energy_flow_velocity_particle_time_magnetic_scale_model\n",
      "paper_two_show_result_finite_property_class_set_function_one\n",
      "material_field_optical_device_application_wave_electromagnetic_design_light_based\n",
      "high_detector_resolution_using_time_performance_energy_based_measurement_result\n",
      "method_data_analysis_result_using_used_one_ground_accuracy_time\n",
      "frequency_method_time_using_analysis_result_function_two_signal_data\n",
      "role_time_ha_play_year_model_dynamic_important_system_recent\n",
      "network_model_structure_study_dynamic_show_node_complex_different_distribution\n",
      "optical_order magnitude_magnitude_measurement_using_order_frequency_high_laser_demonstrate\n",
      "social_information_user_study_result_research_paper_analysis_data_human\n",
      "al_et_et al_quantum_matrix_state_phys_result_system_non\n",
      "paper_data_system_based_present_application_research_approach_using_ha\n",
      "problem_algorithm_optimization_method_solution_optimal_paper_linear_function_based\n",
      "problem_graph_algorithm_time_show_number_result_polynomial_given_also\n",
      "method_learning_propose_model_show_based_art_approach_result_state art\n",
      "show_effect_wave_field_angular_phase_two_mode_beam_structure\n",
      "network_performance_paper_proposed_communication_simulation_result_wireless_channel_scheme\n",
      "data_estimation_model_information_estimate_network_error_sample_based_method\n",
      "energy_electron_state_quantum_field_interaction_result_two_effect_atom\n",
      "channel_system_user_multiple_signal_interference_paper_power_rate_result\n",
      "paper_based_system_propose_ha_however_new_security_proposed_attack\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,26):\n",
    "    print(\"_\".join(gendict[idx] for idx,_  in lda_model.get_topic_terms(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jklinger/anaconda3/envs/py36/lib/python3.6/site-packages/gensim/models/ldamodel.py:775: RuntimeWarning: divide by zero encountered in log\n",
      "  diff = np.log(self.expElogbeta)\n"
     ]
    }
   ],
   "source": [
    "lda_model = LdaMulticore(corpus, num_topics=100, id2word=gendict,\n",
    "                         iterations=100, chunksize=20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result_two_method_based_paper_system_network_using_show_also\n",
      "two_based_result_non_show_case_also_time_function_method\n",
      "method_based_result_show_using_paper_problem_technique_ha_two\n",
      "based_ha_using_paper_high_energy_result_time_used_order\n",
      "system_model_field_show_using_based_state_study_paper_two\n",
      "using_paper_result_used_time_model_high_show_based_two\n",
      "model_result_paper_time_using_show_based_system_ha_study\n",
      "two_show_result_one_time_present_problem_study_based_paper\n",
      "result_using_time_also_based_show_model_ha_used_data\n",
      "paper_result_show_algorithm_approach_model_method_using_problem_based\n",
      "paper_system_based_show_result_time_two_model_proposed_method\n",
      "network_based_method_using_state art_paper_art_state_data_convolutional neural\n",
      "show_also_result_based_model_paper_problem_two_one_time\n",
      "model_result_based_show_paper_data_method_network_proposed_using\n",
      "field_using_two_optical_quantum_time_demonstrate_high_based_result\n",
      "show_result_system_two_time_optical_field_frequency_using_state\n",
      "based_method_result_ha_data_show_paper_learning_using_model\n",
      "result_one_show_two_number_paper_also_prove_order_class\n",
      "paper_first_based_time_problem_two_system_model_using_data\n",
      "system_state_method_two_using_time_quantum_different_also_order\n",
      "paper_ha_network_result_lstm_based_using_approach_show_analysis\n",
      "problem_algorithm_show_time_paper_result_method_number_set_present\n",
      "result_paper_method_two_show_used_study_also_model_system\n",
      "problem_paper_algorithm_based_method_state_system_model_approach_function\n",
      "energy_high_beam_electron_field_result_experiment_system_ha_using\n",
      "time_result_paper_problem_two_system_case_model_network_also\n",
      "proposed_also_paper_based_show_system_model_performance_analysis_result\n",
      "based_paper_model_approach_system_time_result_propose_one_problem\n",
      "paper_data_result_show_performance_based_algorithm_problem_method_network\n",
      "result_using_ha_used_show_model_simulation_high_system_paper\n",
      "network_paper_show_result_system_performance_simulation_model_wireless_communication\n",
      "result_two_paper_also_using_one_ha_problem_state_show\n",
      "paper_also_result_using_two_show_time_present_problem_system\n",
      "time_one_also_paper_new_model_system_two_result_show\n",
      "neural network_network_neural_paper_data_based_show_system_present_using\n",
      "model_show_using_system_study_based_two_result_present_method\n",
      "result_show_time_based_model_also_two_paper_system_one\n",
      "result_based_ha_field_new_paper_model_system_data_one\n",
      "method_result_paper_present_using_model_data_approach_system_problem\n",
      "show_data_network_method_result_algorithm_problem_model_based_paper\n",
      "time_show_result_problem_algorithm_first_bound_also_study_number\n",
      "paper_show_result_one_system_using_time_ha_data_also\n",
      "paper_based_ha_using_show_problem_also_two_work_approach\n",
      "method_paper_using_show_result_model_based_study_two_ha\n",
      "model_show_result_two_also_paper_system_network_using_time\n",
      "also_result_time_show_one_state_case_field_function_study\n",
      "system_result_show_model_paper_ha_problem_based_new_case\n",
      "time_model_ha_result_show_analysis_using_high_based_also\n",
      "model_show_two_result_paper_ha_using_one_number_based\n",
      "show_model_two_result_different_system_study_number_present_time\n",
      "model_time_result_equation_show_system_dynamic_also_study_effect\n",
      "based_paper_model_method_data_algorithm_show_distribution_time_application\n",
      "method_paper_proposed_using_result_based_two_show_function_problem\n",
      "paper_problem_based_two_result_algorithm_number_propose_time_show\n",
      "paper_based_using_result_also_system_new_two_performance_method\n",
      "paper_data_result_based_approach_system_using_information_show_method\n",
      "time_show_result_model_two_first_also_study_using_state\n",
      "system_paper_based_data_ha_present_large_approach_model_application\n",
      "result_show_system_two_also_paper_using_ha_model_based\n",
      "used_high_time_using_system_show_data_based_paper_method\n",
      "model_two_result_time_system_also_field_study_equation_problem\n",
      "two_ha_system_problem_model_also_one_show_paper_case\n",
      "system_one_based_paper_show_also_model_study_time_approach\n",
      "show_result_model_two_paper_present_one_using_based_used\n",
      "result_experimental_model_energy_show_high_simulation_also_flow_material\n",
      "paper_model_result_network_based_data_show_also_using_problem\n",
      "field_show_result_magnetic_time_two_energy_plasma_dynamic_particle\n",
      "model_also_result_show_present_time_system_work_ha_dynamic\n",
      "result_based_ha_show_using_present_field_used_two_time\n",
      "time_two_model_state_using_also_show_method_present_paper\n",
      "paper_theory_system_based_two_show_result_also_problem_one\n",
      "based_model_method_result_performance_using_system_problem_ha_study\n",
      "model_result_based_time_study_first_show_two_system_method\n",
      "time_paper_based_result_study_system_data_present_ha_using\n",
      "based_result_system_method_one_show_paper_used_work_information\n",
      "paper_method_new_present_two_state_result_time_study_using\n",
      "field_based_time_result_model_two_used_using_system_present\n",
      "result_paper_show_study_model_problem_also_two_system_based\n",
      "model_paper_based_show_system_result_present_approach_also_ha\n",
      "based_paper_result_proposed_state_information_method_show_performance_propose\n",
      "result_show_network_paper_performance_method_based_approach_model_proposed\n",
      "show_method_using_paper_approach_problem_data_result_use_based\n",
      "paper_problem_algorithm_time_two_model_ha_based_propose_learning\n",
      "paper_result_show_using_number_ha_field_network_condition_system\n",
      "energy_result_using_model_also_measurement_two_study_theory_state\n",
      "also_show_result_time_problem_algorithm_number_case_paper_ha\n",
      "result_using_paper_show_two_number_time_ha_problem_also\n",
      "time_system_model_using_show_also_two_paper_based_one\n",
      "paper_show_based_also_result_system_model_study_ha_using\n",
      "data_algorithm_time_method_show_result_using_paper_learning_one\n",
      "model_result_paper_based_method_ha_learning_show_data_network\n",
      "paper_model_system_used_based_using_also_ha_two_result\n",
      "field_also_result_model_two_paper_system_magnetic_show_method\n",
      "algorithm_problem_show_using_paper_result_set_method_time_one\n",
      "paper_model_method_based_time_result_using_one_also_two\n",
      "paper_result_show_two_using_case_also_problem_number_based\n",
      "paper_using_result_also_based_model_two_state_problem_system\n",
      "method_result_paper_based_two_problem_system_algorithm_show_state\n",
      "two_result_using_ha_study_effect_frequency_used_simulation_method\n",
      "using_paper_based_method_result_model_used_present_also_two\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,100):\n",
    "    print(\"_\".join(gendict[idx] for idx,_  in lda_model.get_topic_terms(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-8.220221997591302"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_model.log_perplexity(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-8.054961983726416"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_model = LdaMulticore(corpus, num_topics=10, id2word=gendict,\n",
    "                         iterations=100, chunksize=20000)\n",
    "lda_model.log_perplexity(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "coherence_model_lda = CoherenceModel(model=lda_model, corpus=corpus, \n",
    "                                     texts=texts, coherence='c_v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3270612354163167"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coherence_model_lda.get_coherence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
